{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import os\n",
    "import time\n",
    "from random import randint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "options = webdriver.ChromeOptions() \n",
    "options.add_argument(\"download.default_directory=\" + os.getcwd() + \"/downloads\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=&btnG=\n"
     ]
    }
   ],
   "source": [
    "start_page = \"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=&btnG=\"\n",
    "test_name = \"Can Alpaslan\" + \" \" + \"CSUN\"\n",
    "name = \"Can Alpaslan\"\n",
    "print(start_page)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: []\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use pandas create dataframe (df) object that will store the data\n",
    "columns = ['name','paper_type','citation','url','abstract','title','collaborators']\n",
    "citations = pd.DataFrame()\n",
    "#Place the list of names generated previously in the project into the df object\n",
    "citations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df1['e'] = Series(np.random.randn(sLength), index=df1.index)\n",
    "#citations['a'] = pd.Series(test_name, index=citations.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Process Flow\n",
    "-------------------\n",
    "Search professors from start_page by name\n",
    "Click Search\n",
    "Find the first reseach item in the research section\n",
    "Determine type of publication\n",
    "Get Abstract if Abstract exists, if not skip to next\n",
    "Click citation download link\n",
    "Select option (1 = RIS, 2 = BibTex, 3 = Plain text)\n",
    "Select option  (1 = citation 2 = citation and abstract)\n",
    "Download\n",
    "Go to most recent downloaded file\n",
    "Read text from that file\n",
    "Place citation into variable\n",
    "If abstract exists for citation place into abstract variable if no abstract found insert \"No abstract found.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=&btnG=\n",
      "Not in an infinite loop\n"
     ]
    },
    {
     "ename": "UnicodeEncodeError",
     "evalue": "'charmap' codec can't encode character '\\u2010' in position 879: character maps to <undefined>",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m                        Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-b1df46baa549>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    109\u001b[0m         \u001b[0mcitation_record\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mname\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"|\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Title'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Authors'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Date'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Journal'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Volume'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Issue'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Pages'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Publisher'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"| \"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mcitation\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'Description'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\"\\n\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 110\u001b[1;33m         \u001b[0mcitation_file\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation_record\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    111\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[1;34m(self, input, final)\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mUnicodeEncodeError\u001b[0m: 'charmap' codec can't encode character '\\u2010' in position 879: character maps to <undefined>"
     ]
    }
   ],
   "source": [
    "driver = webdriver.Chrome()\n",
    "driver.implicitly_wait(10) # seconds loading implicitly\n",
    "google_scholar = \"https://scholar.google.com/citations?hl=en&view_op=search_authors&mauthors=&btnG=\"\n",
    "#Set driver to go to start_page and search a given name with valid scholar profile\n",
    "driver.get(google_scholar)\n",
    "print(driver.current_url)\n",
    "#Instatiate the webdriver and set to implicitly wait for page objects to load\n",
    "\n",
    "search_bar = driver.find_element_by_class_name('gs_in_txt')\n",
    "search_bar.send_keys(test_name)\n",
    "search_bar.send_keys(Keys.ENTER)\n",
    "\n",
    "\n",
    "#Set driver to click the first profile given as a search result. Will need to be modified to be more general later.\n",
    "view_profile_link = driver.find_element_by_xpath('//*[@id=\"gsc_sa_ccl\"]/div[1]/div/div/h3/a')\n",
    "view_profile_link.click()\n",
    "\n",
    "# To get all the links we need to click the Show More multiple times to show the whole links \n",
    "\n",
    "gs_bpf_wrapper = driver.find_element_by_id(\"gsc_bpf_more\")\n",
    "\n",
    "while not gs_bpf_wrapper.get_attribute(\"disabled\"):\n",
    "    gs_bpf_wrapper.click()\n",
    "    time.sleep(7)\n",
    "\n",
    "print(\"Not in an infinite loop\")\n",
    "\n",
    "#pull the first citation for the page\n",
    "view_citation_links = driver.find_elements_by_class_name('gsc_a_at')\n",
    "#print(view_citation_links)\n",
    "\n",
    "citations = []\n",
    "patents = []\n",
    "other = []\n",
    "\n",
    "citation_file = open('google_scholar_citations.txt', \"a\")\n",
    "patent_file = open('google_scholar_patents.txt', \"a\")\n",
    "\n",
    "for link in view_citation_links:\n",
    "    \n",
    "    title = link.text\n",
    "    \n",
    "    citation = {\n",
    "    \"Authors\" : \"\",\n",
    "    \"Title\" : \"\",\n",
    "    \"Date\" : \"\",\n",
    "    \"Publisher\": \"\",\n",
    "    \"Description\": \"\",\n",
    "    \"Journal\": \"\",\n",
    "    \"Issue\": \"\",\n",
    "    \"Volume\":\"\",\n",
    "    \"Pages\": \"\"\n",
    "    }\n",
    "    \n",
    "    patent = {\n",
    "    \"Inventors\" : \"\",\n",
    "    \"Title\" : \"\",\n",
    "    \"Date\" : \"\",\n",
    "    \"Patent Office\": \"\",\n",
    "    \"Description\": \"\",\n",
    "    \"Application Number\": \"\",\n",
    "    \"Patent Number\": \"\"\n",
    "    }\n",
    "    \n",
    "    link.click()\n",
    "\n",
    "    citation_table = driver.find_element_by_id(\"gsc_vcd_table\")\n",
    "    citation_table_data_objects= citation_table.find_elements_by_class_name(\"gs_scl\")\n",
    "    \n",
    "    data_category = citation_table_data_objects[0].find_element_by_tag_name(\"div\")\n",
    "    \n",
    "    if data_category.text == \"Authors\":\n",
    "        \n",
    "        i = 0\n",
    "        for data in citation_table_data_objects:\n",
    "\n",
    "            data_category = citation_table_data_objects[i].find_element_by_tag_name(\"div\")\n",
    "            \n",
    "            citation_title = driver.find_element_by_id('gsc_vcd_title')\n",
    "            citation[\"Title\"] = citation_title.text\n",
    "\n",
    "            if data_category.text == \"Authors\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Authors\"] = data_field.text\n",
    "            elif data_category.text == \"Publication date\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Date\"] = data_field.text\n",
    "            elif data_category.text == \"Publisher\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Publisher\"] = data_field.text\n",
    "            elif data_category.text == \"Description\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Description\"] = data_field.text\n",
    "            elif data_category.text == \"Journal\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Journal\"] = data_field.text\n",
    "            elif data_category.text == \"Issue\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Issue\"] = data_field.text\n",
    "            elif data_category.text == \"Volume\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Volume\"] = data_field.text\n",
    "            elif data_category.text == \"Pages\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                citation[\"Pages\"] = data_field.text\n",
    "            i = i + 1\n",
    "        citations.append(citation)\n",
    "        \n",
    "        citation_record = name + \"|\" + citation['Title'] + \"| \" + citation['Authors'] + \"| \" + citation['Date'] + \"| \" + citation['Journal'] + \"| \" + citation['Volume'] + \"| \" + citation['Issue'] + \"| \" + citation['Pages'] + \"| \" + citation['Publisher'] + \"| \" + citation['Description'] + \"\\n\" \n",
    "        citation_file.write(str(citation_record))\n",
    "\n",
    "                \n",
    "    elif data_category.text == \"Inventors\":\n",
    "        \n",
    "        for data in citation_table_data_objects:\n",
    "\n",
    "            i = 0\n",
    "            \n",
    "            data_category = citation_table_data_objects[i].find_element_by_tag_name(\"div\")\n",
    "            \n",
    "            citation_title = driver.find_element_by_id('gsc_vcd_title')\n",
    "            citation[\"Title\"] = citation_title.text\n",
    "\n",
    "            if data_category.text == \"Inventors\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Inventors\"] = data_field.text\n",
    "            elif data_category.text == \"Publication date\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Date\"] = data_field.text\n",
    "            elif data_category.text == \"Patent office\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Patent Office\"] = data_field.text\n",
    "            elif data_category.text == \"Description\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Description\"] = data_field.text\n",
    "            elif data_category.text == \"Application number\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Application Number\"] = data_field.text\n",
    "            elif data_category.text == \"Patent number\":\n",
    "                data_field = data.find_element_by_class_name(\"gsc_vcd_value\")\n",
    "                patent[\"Patent Number\"] = data_field.text\n",
    "           \n",
    "            # this is where we would store this record in a pandas dataframe\n",
    "            i += 1\n",
    "        patents.append(patent)\n",
    "        \n",
    "        patent_record = name + \"|\" + citation['Title'] + \"| \" + citation['Inventors'] + \"| \" + citation['Date'] + \"| \" + citation['Patent Office'] + \"| \" + citation['Description'] + \"| \" + citation['Application Number'] + \"| \" + citation['Patent Number'] + \"\\n\" \n",
    "        patent_file.write(patent_record)\n",
    "        \n",
    "       \n",
    "#     else:\n",
    "#         other.append(\"Error: Public \", i , \" did not get captured by program; new decision tree required.\")\n",
    "    \n",
    "    close_table = driver.find_element_by_id(\"gs_md_cita-d-x\")\n",
    "    \n",
    "    \n",
    "    \n",
    "    #webdriver.ActionChains(driver).move_to_element(close_table ).click(close_table ).perform()\n",
    "     \n",
    "    close_table.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "citation_file.close()\n",
    "patent_file.close()    \n",
    "\n",
    "    \n",
    "#view_citation_link.click()\n",
    "\n",
    "#Citation information title, publication date, journal, volume, issue, pages, publisher, abstract.\n",
    "\n",
    "# citations = ['Professor','Authors','Publication_Title', 'URL','Citation']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# citation_table_data = [data.text for data in citation_table_data_objects]\n",
    "# for data in citation_table_data:\n",
    "#     if citation_table.find_elements_by_xpath('//div/div')\n",
    "#     pub_title = driver.find_element_by_class_name('gsc_vcd_title_link')\n",
    "#     citation[\"Title\"] = pub_title.text\n",
    "\n",
    "\n",
    "# pub_date = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[2]/div[2]')\n",
    "# pub_date = pub_date.text\n",
    "# pub_journal = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[3]/div[2]')\n",
    "# pub_journal = pub_journal.text\n",
    "# pub_vol = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[4]/div[2]')\n",
    "# pub_vol = pub_vol.text\n",
    "# pub_iss = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[5]/div[2]')\n",
    "# pub_iss = pub_iss.text\n",
    "# pub_pgs = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[6]/div[2]')\n",
    "# pub_pgs = pub_pgs.text\n",
    "# pub_publisher = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_table\"]/div[7]/div[2]')\n",
    "# pub_publisher = pub_publisher.text\n",
    "# pub_abstr = driver.find_element_by_xpath('//*[@id=\"gsc_vcd_descr\"]/div/div')\n",
    "# pub_abstr = pub_abstr.text \n",
    "# print(pub_title)\n",
    "# print(pub_date)\n",
    "# print(pub_journal)\n",
    "# print(pub_vol)\n",
    "# print(pub_iss)\n",
    "# print(pub_pgs)\n",
    "# print(pub_publisher)\n",
    "# print(pub_abstr)\n",
    "\n",
    "# Retrieve all the urls of the first page\n",
    "#research_a_tags = driver.find_elements_by_xpath(\"html/body/div[2]/main/section[2]/div/div[4]/div[2]/div[2]/div/div/div/div/div/div[2]/div/a\")\n",
    "#urls = [tag.get_attribute(\"href\") for tag in research_a_tags]\n",
    "#titles = [tag.text for tag in research_a_tags]\n",
    "#paper_types = driver.find_elements_by_xpath('html/body/div[2]/main/section[2]/div/div[4]/div[2]/div[2]/div/div/div/div/div/div[3]/div/div/span')\n",
    "#paper_types = [item.text for item in paper_types]\n",
    "#num_research_items -= 100\n",
    "\n",
    "#current_url = driver.current_url\n",
    "\n",
    "#page_count = 2\n",
    "#while num_research_items > 0:\n",
    "    #driver.get(current_url + '/' + str(page_count))\n",
    "    #temp_tags = driver.find_elements_by_xpath(\"html/body/div[2]/main/section[2]/div/div[4]/div[2]/div[2]/div/div/div/div/div/div[2]/div/a\")\n",
    "    #for tag in temp_tags:\n",
    "        #urls.append(tag.get_attribute(\"href\"))\n",
    "        #titles.append(tag.text)\n",
    "    #temp_papers = driver.find_elements_by_xpath('html/body/div[2]/main/section[2]/div/div[4]/div[2]/div[2]/div/div/div/div/div/div[3]/div/div/span')\n",
    "    #for paper in temp_papers:\n",
    "        #paper_types.append(paper.text)\n",
    "    #num_research_items -= 100\n",
    "    #page_count += 1\n",
    "\n",
    "#while \"Full-text available\" in paper_types:\n",
    "    #paper_types.remove(\"Full-text available\")\n",
    "driver.close()\n",
    "\n",
    "if len(other) > 0:\n",
    "    for thing in other:\n",
    "        print(thing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(citations) + len(patents))\n",
    "print(len(citations))\n",
    "for citation in citations:\n",
    "    print(citation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(citation['Title'])\n",
    "# print(citation['Authors'])\n",
    "# print(citation['Date'])\n",
    "# print(citation['Journal'])\n",
    "# print(citation['Volume'])\n",
    "# print(citation['Issue'])\n",
    "# print(citation['Pages'])\n",
    "# print(citation['Publisher'])\n",
    "# print(citation['Description'])\n",
    "\n",
    "record = name + \"|\" + citation['Title'] + \"| \" + citation['Authors'] + \"| \" + citation['Date'] + \"| \" + citation['Journal'] + \"| \" + citation['Volume'] + \"| \" + citation['Issue'] + \"| \" + citation['Pages'] + \"| \" + citation['Publisher'] + \"| \" + citation['Description'] + \"\\n\" \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('jury_rigged_scholars.txt', \"a\")\n",
    "\n",
    "record = name + \"|\" + citation['Title'] + \"| \" + citation['Authors'] + \"| \" + citation['Date'] + \"| \" + citation['Journal'] + \"| \" + citation['Volume'] + \"| \" + citation['Issue'] + \"| \" + citation['Pages'] + \"| \" + citation['Publisher'] + \"| \" + citation['Description'] + \"\\n\" \n",
    "f.write(record)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "{'Inventors': 'Automated methods for simulating a biological network\\nBE Shapiro, ED Mjolsness, A Levchenko - US Patent 7,319,945, 2008\\nCited by 7 Related articles All 2 versions', 'Title': '', 'Date': '', 'Patent Office': '', 'Description': '', 'Application Number': '', 'Patent Number': ''}\n"
     ]
    }
   ],
   "source": [
    "print(len(patents))\n",
    "for patent in patents:\n",
    "    print(patent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count = 0\n",
    "# #for url in urls:\n",
    "# driver = webdriver.Chrome(options=options)\n",
    "# #time.sleep(randint(5,10))\n",
    "\n",
    "# driver.get(urls[0])\n",
    "\n",
    "# # At this point we already have name, title, type, url\n",
    "# # Need citation, collabs, date, DOI, publisher, edition, series, volume, issue, ISSN, ISBN, handle, book title, \n",
    "\n",
    "# if paper_types[0] == 'Article':\n",
    "#     # this should get the DOI and Abstract in one go\n",
    "    \n",
    "#     publication_details = driver.find_elements_by_class_name('publication-details__section')\n",
    "#     print(publication_details)\n",
    "    \n",
    "#     data = publication_details[0].find_elements_by_xpath('//div/div[2]')\n",
    "    \n",
    "#     print(data)\n",
    "    \n",
    "#     #meta = driver.find_elements_by_xpath('html/body/div[2]/main/section/section/div/div[2]')\n",
    "#     #print(meta)\n",
    "#     #doi = meta[0].text.split(\"\")\n",
    "#     #doi = doi[1]\n",
    "#     #abstract = meta[1].text\n",
    "#     # then we'll get the collaborators\n",
    "    \n",
    "    \n",
    "#     # Attempt to get the date\n",
    "#     #date = driver.find_element_by_xpath('html/body/div[2]/main/section/section/div/div/span[2]')\n",
    "    \n",
    "#     #download the citatation\n",
    "    \n",
    "#     # take it apart, perhaps improve it\n",
    "    \n",
    "#     # build a pandas row\n",
    "    \n",
    "#     # add it to the main dataframe\n",
    "#     # end loop\n",
    "    \n",
    "# #print(doi)\n",
    "# #print(abstract)\n",
    "\n",
    "    \n",
    "# #elif paper_type[0] == \"Conference Paper\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# driver.close()\n",
    "#     #count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'dict' and 'dict'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-47-4862c7711b60>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcitation\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpatent\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'dict' and 'dict'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ResearchGate only loads 100 citations per page, if number of citations % 100 = 0 we go to second page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
